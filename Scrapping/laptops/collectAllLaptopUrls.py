from bs4 import BeautifulSoup as BS
import requests

def collectAllLaptopUrls(url: str) -> list[str]:
    '''
    Данная функця предназначена для парсинга сайта. Если более конкретно, \n
    то она собирает ссылки на страницы ноутбуков в список, который в последствии и возвращает. \n
    Сначала она отправляет GET запрос, чтобы получить доступ к HTML странице, потом выбирает \n
    вид, в котором мы получим страницу (page.content - байтовое представление, page.text - строка). \n
    "lxml" - это парсер, который будет использоваться программой. \n
    Чтобы сохранить ссылки, мы объявляем для них список и пробегаемся по массиву, возвращаемому \n
    методом soup.find_all('a', {'class': 'title'}). "a" - это название тега, которые мы ищем, \n
    а {'class': 'title'} - это имя аттрибута тега и его значение \n 
    (в данном случае класс и его название). Чтобы обратиться к нужному нам параметру, \n
    используется следующая запись - link['href']
    '''
    
    page = requests.get(url)
    soup = BS(page.text, 'lxml')
    links = []
    
    for link in soup.find_all('a', {'class': 'title'}): links.append(link['href'])
    
    return links